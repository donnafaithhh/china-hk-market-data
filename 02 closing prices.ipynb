{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:20.358806Z",
     "iopub.status.busy": "2026-02-15T07:27:20.358806Z",
     "iopub.status.idle": "2026-02-15T07:27:20.362419Z",
     "shell.execute_reply": "2026-02-15T07:27:20.362419Z",
     "shell.execute_reply.started": "2026-02-15T07:27:20.358806Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:10:56.088156Z",
     "iopub.status.busy": "2026-02-15T07:10:56.088156Z",
     "iopub.status.idle": "2026-02-15T07:10:56.133759Z",
     "shell.execute_reply": "2026-02-15T07:10:56.133759Z",
     "shell.execute_reply.started": "2026-02-15T07:10:56.088156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guangzhou Baiyun International Airport Co.,ltd.</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dongfeng  Automobile  Co.,LTD</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China World Trade Center Company Ltd.</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beijing Capital Eco-Environment Protection Gro...</td>\n",
       "      <td>600008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Company Code\n",
       "0         SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.       600000\n",
       "1    Guangzhou Baiyun International Airport Co.,ltd.       600004\n",
       "2                      Dongfeng  Automobile  Co.,LTD       600006\n",
       "3              China World Trade Center Company Ltd.       600007\n",
       "4  Beijing Capital Eco-Environment Protection Gro...       600008"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'SSE companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:10:56.135236Z",
     "iopub.status.busy": "2026-02-15T07:10:56.135236Z",
     "iopub.status.idle": "2026-02-15T07:10:56.141584Z",
     "shell.execute_reply": "2026-02-15T07:10:56.141584Z",
     "shell.execute_reply.started": "2026-02-15T07:10:56.135236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600000.SS', '600004.SS', '600006.SS', '600007.SS', '600008.SS']\n"
     ]
    }
   ],
   "source": [
    "tickers_list = companies_df['Company Code'].to_list()\n",
    "tickers_list = [ticker + \".SS\" for ticker in tickers_list]\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:22.940331Z",
     "iopub.status.busy": "2026-02-15T07:27:22.938881Z",
     "iopub.status.idle": "2026-02-15T07:27:22.946369Z",
     "shell.execute_reply": "2026-02-15T07:27:22.945862Z",
     "shell.execute_reply.started": "2026-02-15T07:27:22.940331Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading batch {batch}: {e}\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        if verbose:\n",
    "            print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "\n",
    "        # get the data for each stock\n",
    "        ticker_data = download_info_per_stock(ticker_list[i])\n",
    "\n",
    "        # saving data as a pkl file\n",
    "        if ticker_data is not None and not ticker_data.empty:\n",
    "            filepath = f\"data/{ticker_list[i]}.pkl\"\n",
    "\n",
    "            if override or not os.path.exists(filepath):\n",
    "                ticker_data.to_pickle(filepath)\n",
    "                if verbose == True:\n",
    "                    print(f\"Saved data for {ticker_list[i]}.\")\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print(f\"Skipped {ticker_list[i]}.\")\n",
    "                \n",
    "\n",
    "        # avoid rate limiting\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:23.373769Z",
     "iopub.status.busy": "2026-02-15T07:27:23.373769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['600004.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10005 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600037.SS']: Timeout('Failed to perform, curl: (28) Connection timed out after 10005 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600120.SS']: SSLError('Failed to perform, curl: (35) Recv failure: Connection was reset. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600128.SS']: Timeout('Failed to perform, curl: (28) Operation timed out after 10003 milliseconds with 99547 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600129.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10004 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600131.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10003 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600132.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10007 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600133.SS']: DNSError('Failed to perform, curl: (6) Could not resolve host: query2.finance.yahoo.com. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600135.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10009 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Disregarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:53.555182Z",
     "iopub.status.busy": "2026-02-15T06:59:53.555182Z",
     "iopub.status.idle": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply.started": "2026-02-15T06:59:53.555182Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:29.236321Z",
     "iopub.status.busy": "2026-02-15T06:59:29.236321Z",
     "iopub.status.idle": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply.started": "2026-02-15T06:59:29.236321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
