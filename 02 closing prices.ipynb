{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:20.358806Z",
     "iopub.status.busy": "2026-02-15T07:27:20.358806Z",
     "iopub.status.idle": "2026-02-15T07:27:20.362419Z",
     "shell.execute_reply": "2026-02-15T07:27:20.362419Z",
     "shell.execute_reply.started": "2026-02-15T07:27:20.358806Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:10:56.088156Z",
     "iopub.status.busy": "2026-02-15T07:10:56.088156Z",
     "iopub.status.idle": "2026-02-15T07:10:56.133759Z",
     "shell.execute_reply": "2026-02-15T07:10:56.133759Z",
     "shell.execute_reply.started": "2026-02-15T07:10:56.088156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guangzhou Baiyun International Airport Co.,ltd.</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dongfeng  Automobile  Co.,LTD</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China World Trade Center Company Ltd.</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beijing Capital Eco-Environment Protection Gro...</td>\n",
       "      <td>600008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Company Code\n",
       "0         SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.       600000\n",
       "1    Guangzhou Baiyun International Airport Co.,ltd.       600004\n",
       "2                      Dongfeng  Automobile  Co.,LTD       600006\n",
       "3              China World Trade Center Company Ltd.       600007\n",
       "4  Beijing Capital Eco-Environment Protection Gro...       600008"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'SSE companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:10:56.135236Z",
     "iopub.status.busy": "2026-02-15T07:10:56.135236Z",
     "iopub.status.idle": "2026-02-15T07:10:56.141584Z",
     "shell.execute_reply": "2026-02-15T07:10:56.141584Z",
     "shell.execute_reply.started": "2026-02-15T07:10:56.135236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600000.SS', '600004.SS', '600006.SS', '600007.SS', '600008.SS']\n"
     ]
    }
   ],
   "source": [
    "tickers_list = companies_df['Company Code'].to_list()\n",
    "tickers_list = [ticker + \".SS\" for ticker in tickers_list]\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa8e1e4-d98f-4536-b36d-212ef96f6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:34:21.316768Z",
     "iopub.status.busy": "2026-02-15T07:34:21.316768Z",
     "iopub.status.idle": "2026-02-15T07:34:21.320839Z",
     "shell.execute_reply": "2026-02-15T07:34:21.320839Z",
     "shell.execute_reply.started": "2026-02-15T07:34:21.316768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000.SS\n",
      "SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(tickers_list[0])\n",
    "print(companies_df['Company Name'][0])\n",
    "print(len(companies_df) == len(tickers_list)) # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:22.940331Z",
     "iopub.status.busy": "2026-02-15T07:27:22.938881Z",
     "iopub.status.idle": "2026-02-15T07:27:22.946369Z",
     "shell.execute_reply": "2026-02-15T07:27:22.945862Z",
     "shell.execute_reply.started": "2026-02-15T07:27:22.940331Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading batch {batch}: {e}\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        if verbose:\n",
    "            print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "\n",
    "        # get the data for each stock\n",
    "        ticker_data = download_info_per_stock(ticker_list[i])\n",
    "\n",
    "        # saving data as a pkl file\n",
    "        if ticker_data is not None and not ticker_data.empty:\n",
    "            filepath = f\"data/{companies_df[i]}.pkl\"\n",
    "\n",
    "            if override or not os.path.exists(filepath):\n",
    "                ticker_data.to_pickle(filepath)\n",
    "                if verbose == True:\n",
    "                    print(f\"Saved data for {ticker_list[i]}.\")\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print(f\"Skipped {ticker_list[i]}.\")\n",
    "                \n",
    "\n",
    "        # avoid rate limiting\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:27:23.373769Z",
     "iopub.status.busy": "2026-02-15T07:27:23.373769Z",
     "iopub.status.idle": "2026-02-15T07:32:53.757377Z",
     "shell.execute_reply": "2026-02-15T07:32:53.757377Z",
     "shell.execute_reply.started": "2026-02-15T07:27:23.373769Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['600004.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10005 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600037.SS']: Timeout('Failed to perform, curl: (28) Connection timed out after 10005 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600120.SS']: SSLError('Failed to perform, curl: (35) Recv failure: Connection was reset. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600128.SS']: Timeout('Failed to perform, curl: (28) Operation timed out after 10003 milliseconds with 99547 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600129.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10004 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600131.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10003 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600132.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10007 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600133.SS']: DNSError('Failed to perform, curl: (6) Could not resolve host: query2.finance.yahoo.com. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['600135.SS']: Timeout('Failed to perform, curl: (28) Resolving timed out after 10009 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msave_info_per_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36msave_info_per_stock\u001b[39m\u001b[34m(ticker_list, delay, verbose, override, start_date, end_date)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading for ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker_list[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# get the data for each stock\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m ticker_data = \u001b[43mdownload_info_per_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# saving data as a pkl file\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ticker_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ticker_data.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mdownload_info_per_stock\u001b[39m\u001b[34m(ticker, verbose, start_date, end_date)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_info_per_stock\u001b[39m(ticker, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m      3\u001b[39m                             start_date=\u001b[33m'\u001b[39m\u001b[33m2000-01-01\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      4\u001b[39m                             end_date=\u001b[33m'\u001b[39m\u001b[33m2026-01-01\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m             \u001b[38;5;66;03m# get data for the ticker\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m             ticker_data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(ticker_data)\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\utils.py:92\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\multi.py:167\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[39m\n\u001b[32m    160\u001b[39m         _download_one_threaded(ticker, period=period, interval=interval,\n\u001b[32m    161\u001b[39m                                start=start, end=end, prepost=prepost,\n\u001b[32m    162\u001b[39m                                actions=actions, auto_adjust=auto_adjust,\n\u001b[32m    163\u001b[39m                                back_adjust=back_adjust, repair=repair, keepna=keepna,\n\u001b[32m    164\u001b[39m                                progress=(progress \u001b[38;5;129;01mand\u001b[39;00m i > \u001b[32m0\u001b[39m),\n\u001b[32m    165\u001b[39m                                rounding=rounding, timeout=timeout)\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared._DFS) < \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[43m_time\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Disregarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:53.555182Z",
     "iopub.status.busy": "2026-02-15T06:59:53.555182Z",
     "iopub.status.idle": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply.started": "2026-02-15T06:59:53.555182Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:29.236321Z",
     "iopub.status.busy": "2026-02-15T06:59:29.236321Z",
     "iopub.status.idle": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply.started": "2026-02-15T06:59:29.236321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
