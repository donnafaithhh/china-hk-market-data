{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:35.509957Z",
     "iopub.status.busy": "2026-02-15T07:38:35.509957Z",
     "iopub.status.idle": "2026-02-15T07:38:35.513652Z",
     "shell.execute_reply": "2026-02-15T07:38:35.513652Z",
     "shell.execute_reply.started": "2026-02-15T07:38:35.509957Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:38.240275Z",
     "iopub.status.busy": "2026-02-15T07:38:38.240275Z",
     "iopub.status.idle": "2026-02-15T07:38:38.248384Z",
     "shell.execute_reply": "2026-02-15T07:38:38.248384Z",
     "shell.execute_reply.started": "2026-02-15T07:38:38.240275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guangzhou Baiyun International Airport Co.,ltd.</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dongfeng  Automobile  Co.,LTD</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China World Trade Center Company Ltd.</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beijing Capital Eco-Environment Protection Gro...</td>\n",
       "      <td>600008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Company Code\n",
       "0         SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.       600000\n",
       "1    Guangzhou Baiyun International Airport Co.,ltd.       600004\n",
       "2                      Dongfeng  Automobile  Co.,LTD       600006\n",
       "3              China World Trade Center Company Ltd.       600007\n",
       "4  Beijing Capital Eco-Environment Protection Gro...       600008"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'SSE companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:39.006527Z",
     "iopub.status.busy": "2026-02-15T07:38:39.006527Z",
     "iopub.status.idle": "2026-02-15T07:38:39.010876Z",
     "shell.execute_reply": "2026-02-15T07:38:39.010876Z",
     "shell.execute_reply.started": "2026-02-15T07:38:39.006527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600000.SS', '600004.SS', '600006.SS', '600007.SS', '600008.SS']\n"
     ]
    }
   ],
   "source": [
    "tickers_list = companies_df['Company Code'].to_list()\n",
    "tickers_list = [ticker + \".SS\" for ticker in tickers_list]\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aa8e1e4-d98f-4536-b36d-212ef96f6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:39.861538Z",
     "iopub.status.busy": "2026-02-15T07:38:39.861538Z",
     "iopub.status.idle": "2026-02-15T07:38:39.865935Z",
     "shell.execute_reply": "2026-02-15T07:38:39.865935Z",
     "shell.execute_reply.started": "2026-02-15T07:38:39.861538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000.SS\n",
      "SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(tickers_list[0])\n",
    "print(companies_df['Company Name'][0])\n",
    "print(len(companies_df) == len(tickers_list)) # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:41.738449Z",
     "iopub.status.busy": "2026-02-15T07:38:41.737331Z",
     "iopub.status.idle": "2026-02-15T07:38:41.744398Z",
     "shell.execute_reply": "2026-02-15T07:38:41.743889Z",
     "shell.execute_reply.started": "2026-02-15T07:38:41.738449Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading batch {batch}: {e}\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        if verbose:\n",
    "            print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "\n",
    "        # get the data for each stock\n",
    "        ticker_data = download_info_per_stock(ticker_list[i])\n",
    "\n",
    "        # saving data as a pkl file\n",
    "        if ticker_data is not None and not ticker_data.empty:\n",
    "            filepath = f\"data/{companies_df[i]}.pkl\"\n",
    "\n",
    "            if override or not os.path.exists(filepath):\n",
    "                ticker_data.to_pickle(filepath)\n",
    "                if verbose == True:\n",
    "                    print(f\"Saved data for {ticker_list[i]}.\")\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print(f\"Skipped {ticker_list[i]}.\")\n",
    "                \n",
    "\n",
    "        # avoid rate limiting\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:38:43.507543Z",
     "iopub.status.busy": "2026-02-15T07:38:43.507543Z",
     "iopub.status.idle": "2026-02-15T07:38:47.821646Z",
     "shell.execute_reply": "2026-02-15T07:38:47.821646Z",
     "shell.execute_reply.started": "2026-02-15T07:38:43.507543Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msave_info_per_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36msave_info_per_stock\u001b[39m\u001b[34m(ticker_list, delay, verbose, override, start_date, end_date)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# saving data as a pkl file\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ticker_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ticker_data.empty:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     filepath = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcompanies_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m override \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(filepath):\n\u001b[32m     41\u001b[39m         ticker_data.to_pickle(filepath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Disregarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:53.555182Z",
     "iopub.status.busy": "2026-02-15T06:59:53.555182Z",
     "iopub.status.idle": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply": "2026-02-15T06:59:53.570701Z",
     "shell.execute_reply.started": "2026-02-15T06:59:53.555182Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T06:59:29.236321Z",
     "iopub.status.busy": "2026-02-15T06:59:29.236321Z",
     "iopub.status.idle": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply": "2026-02-15T06:59:29.256162Z",
     "shell.execute_reply.started": "2026-02-15T06:59:29.236321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
