{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f7dc1-1969-4cb3-9ffd-cc4b60ba2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -qq -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:54.927018Z",
     "iopub.status.busy": "2026-02-15T08:19:54.927018Z",
     "iopub.status.idle": "2026-02-15T08:19:57.107423Z",
     "shell.execute_reply": "2026-02-15T08:19:57.107423Z",
     "shell.execute_reply.started": "2026-02-15T08:19:54.927018Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:57.108430Z",
     "iopub.status.busy": "2026-02-15T08:19:57.108430Z",
     "iopub.status.idle": "2026-02-15T08:19:57.123772Z",
     "shell.execute_reply": "2026-02-15T08:19:57.123772Z",
     "shell.execute_reply.started": "2026-02-15T08:19:57.108430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guangzhou Baiyun International Airport Co.,ltd.</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dongfeng  Automobile  Co.,LTD</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China World Trade Center Company Ltd.</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beijing Capital Eco-Environment Protection Gro...</td>\n",
       "      <td>600008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Company Code\n",
       "0         SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.       600000\n",
       "1    Guangzhou Baiyun International Airport Co.,ltd.       600004\n",
       "2                      Dongfeng  Automobile  Co.,LTD       600006\n",
       "3              China World Trade Center Company Ltd.       600007\n",
       "4  Beijing Capital Eco-Environment Protection Gro...       600008"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'SSE companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:57.125111Z",
     "iopub.status.busy": "2026-02-15T08:19:57.125111Z",
     "iopub.status.idle": "2026-02-15T08:19:57.129527Z",
     "shell.execute_reply": "2026-02-15T08:19:57.129014Z",
     "shell.execute_reply.started": "2026-02-15T08:19:57.125111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600000.SS', '600004.SS', '600006.SS', '600007.SS', '600008.SS']\n"
     ]
    }
   ],
   "source": [
    "tickers_list = companies_df['Company Code'].to_list()\n",
    "tickers_list = [ticker + \".SS\" for ticker in tickers_list]\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa8e1e4-d98f-4536-b36d-212ef96f6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:57.129527Z",
     "iopub.status.busy": "2026-02-15T08:19:57.129527Z",
     "iopub.status.idle": "2026-02-15T08:19:57.135751Z",
     "shell.execute_reply": "2026-02-15T08:19:57.135751Z",
     "shell.execute_reply.started": "2026-02-15T08:19:57.129527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000.SS\n",
      "SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(tickers_list[0])\n",
    "print(companies_df['Company Name'][0])\n",
    "print(len(companies_df) == len(tickers_list)) # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:57.137212Z",
     "iopub.status.busy": "2026-02-15T08:19:57.137212Z",
     "iopub.status.idle": "2026-02-15T08:19:57.143201Z",
     "shell.execute_reply": "2026-02-15T08:19:57.143201Z",
     "shell.execute_reply.started": "2026-02-15T08:19:57.137212Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False,\n",
    "                timeout=120 # in case of slow internet, in seconds\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading batch {batch}: {e}\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        # declare company name and filepath\n",
    "        ticker_name = companies_df['Company Name'][i]\n",
    "        filepath = f\"data/{ticker_name}.pkl\"\n",
    "\n",
    "        # skip if not override and file exists\n",
    "        if not override and os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {ticker_name}.\")\n",
    "                continue\n",
    "                \n",
    "        # get the data for each stock\n",
    "        if verbose:\n",
    "            print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "        ticker_data = download_info_per_stock(ticker_list[i],\n",
    "                                              start_date=start_date,\n",
    "                                              end_date=end_date)\n",
    "\n",
    "        # saving data as a pkl file\n",
    "        if ticker_data is not None and not ticker_data.empty:\n",
    "            ticker_data.to_pickle(filepath)\n",
    "            if verbose == True:\n",
    "                print(f\"Saved data for {ticker_list[i]}.\")\n",
    "        \n",
    "        # avoid rate limiting\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:19:57.144219Z",
     "iopub.status.busy": "2026-02-15T08:19:57.144219Z",
     "iopub.status.idle": "2026-02-15T08:20:03.991986Z",
     "shell.execute_reply": "2026-02-15T08:20:03.991986Z",
     "shell.execute_reply.started": "2026-02-15T08:19:57.144219Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['600000.SS']: DNSError('Failed to perform, curl: (6) Could not resolve host: query1.finance.yahoo.com. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msave_info_per_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36msave_info_per_stock\u001b[39m\u001b[34m(ticker_list, delay, verbose, override, start_date, end_date)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading for ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker_list[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m ticker_data = \u001b[43mdownload_info_per_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# saving data as a pkl file\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ticker_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ticker_data.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mdownload_info_per_stock\u001b[39m\u001b[34m(ticker, verbose, start_date, end_date)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_info_per_stock\u001b[39m(ticker, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m      3\u001b[39m                             start_date=\u001b[33m'\u001b[39m\u001b[33m2000-01-01\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      4\u001b[39m                             end_date=\u001b[33m'\u001b[39m\u001b[33m2026-01-01\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m             \u001b[38;5;66;03m# get data for the ticker\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m             ticker_data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# in case of slow internet, in seconds\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(ticker_data)\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\utils.py:92\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\multi.py:167\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[39m\n\u001b[32m    160\u001b[39m         _download_one_threaded(ticker, period=period, interval=interval,\n\u001b[32m    161\u001b[39m                                start=start, end=end, prepost=prepost,\n\u001b[32m    162\u001b[39m                                actions=actions, auto_adjust=auto_adjust,\n\u001b[32m    163\u001b[39m                                back_adjust=back_adjust, repair=repair, keepna=keepna,\n\u001b[32m    164\u001b[39m                                progress=(progress \u001b[38;5;129;01mand\u001b[39;00m i > \u001b[32m0\u001b[39m),\n\u001b[32m    165\u001b[39m                                rounding=rounding, timeout=timeout)\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared._DFS) < \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[43m_time\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Discarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T08:20:03.992997Z",
     "iopub.status.idle": "2026-02-15T08:20:03.992997Z",
     "shell.execute_reply": "2026-02-15T08:20:03.992997Z",
     "shell.execute_reply.started": "2026-02-15T08:20:03.992997Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T08:20:03.994545Z",
     "iopub.status.idle": "2026-02-15T08:20:03.994545Z",
     "shell.execute_reply": "2026-02-15T08:20:03.994545Z",
     "shell.execute_reply.started": "2026-02-15T08:20:03.994545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
