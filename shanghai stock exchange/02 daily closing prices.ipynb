{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7f7dc1-1969-4cb3-9ffd-cc4b60ba2c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:15.789263Z",
     "iopub.status.busy": "2026-02-15T11:16:15.789263Z",
     "iopub.status.idle": "2026-02-15T11:16:17.264520Z",
     "shell.execute_reply": "2026-02-15T11:16:17.263501Z",
     "shell.execute_reply.started": "2026-02-15T11:16:15.789263Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -qq -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:17.264520Z",
     "iopub.status.busy": "2026-02-15T11:16:17.264520Z",
     "iopub.status.idle": "2026-02-15T11:16:19.040947Z",
     "shell.execute_reply": "2026-02-15T11:16:19.040947Z",
     "shell.execute_reply.started": "2026-02-15T11:16:17.264520Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Daily Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.042338Z",
     "iopub.status.busy": "2026-02-15T11:16:19.042338Z",
     "iopub.status.idle": "2026-02-15T11:16:19.058305Z",
     "shell.execute_reply": "2026-02-15T11:16:19.057800Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.042338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guangzhou Baiyun International Airport Co.,ltd.</td>\n",
       "      <td>600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dongfeng  Automobile  Co.,LTD</td>\n",
       "      <td>600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China World Trade Center Company Ltd.</td>\n",
       "      <td>600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beijing Capital Eco-Environment Protection Gro...</td>\n",
       "      <td>600008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Company Code\n",
       "0         SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.       600000\n",
       "1    Guangzhou Baiyun International Airport Co.,ltd.       600004\n",
       "2                      Dongfeng  Automobile  Co.,LTD       600006\n",
       "3              China World Trade Center Company Ltd.       600007\n",
       "4  Beijing Capital Eco-Environment Protection Gro...       600008"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'SSE companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.059311Z",
     "iopub.status.busy": "2026-02-15T11:16:19.059311Z",
     "iopub.status.idle": "2026-02-15T11:16:19.063096Z",
     "shell.execute_reply": "2026-02-15T11:16:19.063096Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.059311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600000.SS', '600004.SS', '600006.SS', '600007.SS', '600008.SS']\n"
     ]
    }
   ],
   "source": [
    "# add the suffix to make it compatible with yfinance\n",
    "tickers_list = companies_df['Company Code'].to_list()\n",
    "tickers_list = [ticker + \".SS\" for ticker in tickers_list]\n",
    "\n",
    "# check if it worked\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa8e1e4-d98f-4536-b36d-212ef96f6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.064406Z",
     "iopub.status.busy": "2026-02-15T11:16:19.064406Z",
     "iopub.status.idle": "2026-02-15T11:16:19.068562Z",
     "shell.execute_reply": "2026-02-15T11:16:19.068562Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.064406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000.SS\n",
      "SHANGHAI PUDONG DEVELOPMENT BANK CO., LTD.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(tickers_list[0])\n",
    "print(companies_df['Company Name'][0])\n",
    "print(len(companies_df) == len(tickers_list)) # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb52424-e34a-452f-9f1e-cc6cbcaec6fa",
   "metadata": {},
   "source": [
    "Some company names have forbidden characters which can hinder them from becoming a file name.\n",
    "They have to be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71ef4ee-145e-4da8-8b1a-905a8b95e8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.069910Z",
     "iopub.status.busy": "2026-02-15T11:16:19.069910Z",
     "iopub.status.idle": "2026-02-15T11:16:19.078004Z",
     "shell.execute_reply": "2026-02-15T11:16:19.078004Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.069910Z"
    }
   },
   "outputs": [],
   "source": [
    "# forbidden Windows filename characters\n",
    "forbidden_chars = r'[<>:\"/\\\\|?*]'\n",
    "\n",
    "# remove forbidden characters and extra spaces\n",
    "companies_df['Company Name'] = companies_df['Company Name'].apply(\n",
    "    lambda x: re.sub(forbidden_chars, '', x)\n",
    ")\n",
    "companies_df['Company Name'] = companies_df['Company Name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1104c08-8f8e-4b99-87dd-a014bef2ccef",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.079413Z",
     "iopub.status.busy": "2026-02-15T11:16:19.079413Z",
     "iopub.status.idle": "2026-02-15T11:16:19.086678Z",
     "shell.execute_reply": "2026-02-15T11:16:19.086678Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.079413Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False,\n",
    "                timeout=120 # in case of slow internet, in seconds\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading {ticker}.\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        # declare company name and filepath\n",
    "        ticker_name = companies_df['Company Name'][i]\n",
    "        filepath = f\"data/{ticker_name}.pkl\"\n",
    "\n",
    "        # skip if not override and file exists\n",
    "        if override == False and os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {ticker_name}.\")\n",
    "                continue\n",
    "        else:                    \n",
    "            # get the data for each stock\n",
    "            if verbose:\n",
    "                print()\n",
    "                print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "            ticker_data = download_info_per_stock(ticker_list[i],\n",
    "                                                  start_date=start_date,\n",
    "                                                  end_date=end_date)\n",
    "    \n",
    "            # saving data as a pkl file\n",
    "            if ticker_data is not None and not ticker_data.empty:\n",
    "                ticker_data.to_pickle(filepath)\n",
    "                if verbose == True:\n",
    "                    print(f\"Saved data for {ticker_name}.\")\n",
    "            \n",
    "            # avoid rate limiting\n",
    "            time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:19.087689Z",
     "iopub.status.busy": "2026-02-15T11:16:19.087689Z",
     "iopub.status.idle": "2026-02-15T11:16:22.439926Z",
     "shell.execute_reply": "2026-02-15T11:16:22.439926Z",
     "shell.execute_reply.started": "2026-02-15T11:16:19.087689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['603194.SS']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done downloading all data!\n"
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753dc122-0dbb-448c-8ac6-5d61dade3c68",
   "metadata": {},
   "source": [
    "Note: The code above takes around 40-50 minutes to completely run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Discarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:22.441378Z",
     "iopub.status.busy": "2026-02-15T11:16:22.441378Z",
     "iopub.status.idle": "2026-02-15T11:16:22.448105Z",
     "shell.execute_reply": "2026-02-15T11:16:22.448105Z",
     "shell.execute_reply.started": "2026-02-15T11:16:22.441378Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T11:16:22.449570Z",
     "iopub.status.busy": "2026-02-15T11:16:22.449570Z",
     "iopub.status.idle": "2026-02-15T11:16:22.453674Z",
     "shell.execute_reply": "2026-02-15T11:16:22.453156Z",
     "shell.execute_reply.started": "2026-02-15T11:16:22.449570Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
