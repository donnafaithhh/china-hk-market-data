{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be29dbe5-b15d-401c-ba84-734aba72b9f2",
   "metadata": {},
   "source": [
    "This notebook was created by Donna Faith Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7f7dc1-1969-4cb3-9ffd-cc4b60ba2c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:37.734171Z",
     "iopub.status.busy": "2026-02-18T14:24:37.734171Z",
     "iopub.status.idle": "2026-02-18T14:24:39.388043Z",
     "shell.execute_reply": "2026-02-18T14:24:39.388043Z",
     "shell.execute_reply.started": "2026-02-18T14:24:37.734171Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -qq -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9795ae54-3603-4be9-9824-94113700c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:39.390050Z",
     "iopub.status.busy": "2026-02-18T14:24:39.388043Z",
     "iopub.status.idle": "2026-02-18T14:24:41.121548Z",
     "shell.execute_reply": "2026-02-18T14:24:41.121548Z",
     "shell.execute_reply.started": "2026-02-18T14:24:39.390050Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "# data gathering\n",
    "import yfinance as yf\n",
    "import time\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca6c4-70a8-4863-a39c-f94f28b3a6b1",
   "metadata": {},
   "source": [
    "## Daily Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6182-b43a-438d-b402-6721c35f1ce3",
   "metadata": {},
   "source": [
    "## Stock Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc69d9bc-3016-4cc4-b351-9b26ffb9d9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.123553Z",
     "iopub.status.busy": "2026-02-18T14:24:41.123553Z",
     "iopub.status.idle": "2026-02-18T14:24:41.133149Z",
     "shell.execute_reply": "2026-02-18T14:24:41.132132Z",
     "shell.execute_reply.started": "2026-02-18T14:24:41.123553Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = 'HKEX companies list.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    companies_df = pickle.load(f)\n",
    "companies_df.head()\n",
    "companies_df = companies_df[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5279c7d5-5125-4bce-9838-fd172d8a0169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.134515Z",
     "iopub.status.busy": "2026-02-18T14:24:41.133450Z",
     "iopub.status.idle": "2026-02-18T14:24:41.167172Z",
     "shell.execute_reply": "2026-02-18T14:24:41.166440Z",
     "shell.execute_reply.started": "2026-02-18T14:24:41.134515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0700.HK', '1398.HK', '9988.HK', '1288.HK', '4333.HK']\n"
     ]
    }
   ],
   "source": [
    "# add the suffix to make it compatible with yfinance\n",
    "tickers_list = companies_df['Symbol'].to_list()\n",
    "tickers_list = [ticker + \".HK\" for ticker in tickers_list]\n",
    "\n",
    "# check if it worked\n",
    "print(tickers_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa8e1e4-d98f-4536-b36d-212ef96f6e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.167172Z",
     "iopub.status.busy": "2026-02-18T14:24:41.167172Z",
     "iopub.status.idle": "2026-02-18T14:24:41.175983Z",
     "shell.execute_reply": "2026-02-18T14:24:41.175983Z",
     "shell.execute_reply.started": "2026-02-18T14:24:41.167172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0700.HK\n",
      "Tencent Holdings Limited\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(tickers_list[0])\n",
    "print(companies_df['Company Name'][0])\n",
    "print(len(companies_df) == len(tickers_list)) # should be True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121568-7edc-407f-be44-acb5c883bca2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb52424-e34a-452f-9f1e-cc6cbcaec6fa",
   "metadata": {},
   "source": [
    "Some company names have forbidden characters which can hinder them from becoming a file name.\n",
    "They have to be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71ef4ee-145e-4da8-8b1a-905a8b95e8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.175983Z",
     "iopub.status.busy": "2026-02-18T14:24:41.175983Z",
     "iopub.status.idle": "2026-02-18T14:24:41.189021Z",
     "shell.execute_reply": "2026-02-18T14:24:41.189021Z",
     "shell.execute_reply.started": "2026-02-18T14:24:41.175983Z"
    }
   },
   "outputs": [],
   "source": [
    "# forbidden Windows filename characters\n",
    "forbidden_chars = r'[<>:\"/\\\\|?*]'\n",
    "\n",
    "# remove forbidden characters and extra spaces\n",
    "companies_df['Company Name'] = companies_df['Company Name'].apply(\n",
    "    lambda x: re.sub(forbidden_chars, '', x)\n",
    ")\n",
    "companies_df['Company Name'] = companies_df['Company Name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1104c08-8f8e-4b99-87dd-a014bef2ccef",
   "metadata": {},
   "source": [
    "## yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dda45a-3a8a-488e-8e32-442edc333df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.192765Z",
     "iopub.status.busy": "2026-02-18T14:24:41.190957Z",
     "iopub.status.idle": "2026-02-18T14:24:41.203496Z",
     "shell.execute_reply": "2026-02-18T14:24:41.203496Z",
     "shell.execute_reply.started": "2026-02-18T14:24:41.192765Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull individual stock data from yfinance\n",
    "def download_info_per_stock(ticker, verbose=False, \n",
    "                            start_date='2000-01-01', \n",
    "                            end_date='2026-01-01'):\n",
    "        try:\n",
    "            # get data for the ticker\n",
    "            ticker_data = yf.download(\n",
    "                ticker,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False,\n",
    "                timeout=120 # in case of slow internet, in seconds\n",
    "            )\n",
    "            return pd.DataFrame(ticker_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error downloading {ticker}.\")\n",
    "            return None\n",
    "\n",
    "# saving individual stock data\n",
    "def save_info_per_stock(ticker_list, delay=1, \n",
    "                        verbose=False, override=False,\n",
    "                        start_date='2000-01-01', \n",
    "                        end_date='2026-01-01'):\n",
    "    \n",
    "    # create the data folder\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(ticker_list)):\n",
    "        # declare company name and filepath\n",
    "        ticker_name = companies_df['Company Name'][i]\n",
    "        filepath = f\"data/{ticker_name}.pkl\"\n",
    "\n",
    "        # skip if not override and file exists\n",
    "        if override == False and os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {ticker_name}.\")\n",
    "                continue\n",
    "        else:                    \n",
    "            # get the data for each stock\n",
    "            if verbose:\n",
    "                print()\n",
    "                print(f\"Downloading for ticker: {ticker_list[i]}\")\n",
    "            ticker_data = download_info_per_stock(ticker_list[i],\n",
    "                                                  start_date=start_date,\n",
    "                                                  end_date=end_date)\n",
    "    \n",
    "            # saving data as a pkl file\n",
    "            if ticker_data is not None and not ticker_data.empty:\n",
    "                ticker_data.to_pickle(filepath)\n",
    "                if verbose == True:\n",
    "                    print(f\"Saved data for {ticker_name}.\")\n",
    "            \n",
    "            # avoid rate limiting\n",
    "            time.sleep(delay)\n",
    "\n",
    "    print(\"Done downloading all data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8181c9a-7d21-4646-98c5-91850bacd8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T14:24:41.203496Z",
     "iopub.status.busy": "2026-02-18T14:24:41.203496Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['2714.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['0100.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01)')\n",
      "\n",
      "1 Failed download:\n",
      "['3986.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['2513.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['6809.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['9980.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['0501.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01)')\n",
      "\n",
      "1 Failed download:\n",
      "['0470.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "Failed to get ticker '6082.HK' reason: Failed to perform, curl: (28) Connection timed out after 106381 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "\n",
      "1 Failed download:\n",
      "['6082.HK']: DNSError('Failed to perform, curl: (6) Could not resolve host: query2.finance.yahoo.com. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "Failed to get ticker '2016.HK' reason: Failed to perform, curl: (7) Failed to connect to query2.finance.yahoo.com port 443 after 21 ms: Could not connect to server. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "\n",
      "1 Failed download:\n",
      "['2016.HK']: ConnectionError('Failed to perform, curl: (7) Failed to connect to query2.finance.yahoo.com port 443 after 2 ms: Could not connect to server. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['1768.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['3200.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['9903.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['2706.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['0699.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01)')\n",
      "\n",
      "1 Failed download:\n",
      "['9981.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['0638.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01)')\n",
      "\n",
      "1 Failed download:\n",
      "['2675.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['9611.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['2768.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n",
      "\n",
      "1 Failed download:\n",
      "['0600.HK']: YFPricesMissingError('possibly delisted; no price data found  (1d 2000-01-01 -> 2026-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 946656000, endDate = 1767196800\")')\n"
     ]
    }
   ],
   "source": [
    "save_info_per_stock(tickers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753dc122-0dbb-448c-8ac6-5d61dade3c68",
   "metadata": {},
   "source": [
    "Note: The code above takes around 40-50 minutes to completely run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee36779-c128-4534-a8f0-ae5736921155",
   "metadata": {},
   "source": [
    "## Discarded Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e10a-fb80-4288-a3b5-5bcaff0642ff",
   "metadata": {},
   "source": [
    "This code was disregarded because the files it generated were too big to be committed on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3335322-ac77-4980-84cd-f199c1ee4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare start and end dates\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2026-01-01'\n",
    "\n",
    "def download_stocks_in_batches(tickers, batch_size=5, delay=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Download stock data in batches to avoid rate limiting\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        if verbose:\n",
    "            print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "        try:\n",
    "            # Download the batch\n",
    "            batch_data = yf.download(\n",
    "                batch,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            # Extract closing prices for this batch\n",
    "            if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "                closes = batch_data['Close']\n",
    "                if isinstance(closes, pd.Series):\n",
    "                    all_data[batch[0]] = closes\n",
    "                else:\n",
    "                    for ticker in closes.columns:\n",
    "                        all_data[ticker] = closes[ticker]\n",
    "                if verbose:\n",
    "                    print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "            else:\n",
    "                print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        if i + batch_size < len(tickers):\n",
    "            if verbose:\n",
    "                print(f\"Waiting {delay} seconds before next batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        return pd.DataFrame(all_data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76f0c1-929f-42b6-927b-9444bbad8973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the closing prices\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     tickers_list, \n",
    "#     batch_size=5, \n",
    "#     delay=5\n",
    "# )\n",
    "\n",
    "# # removing unnecessary columns and rows\n",
    "# closing_df.dropna(how='all', axis=1, inplace=True)\n",
    "# closing_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "# # # save to pkl\n",
    "# # if not closing_df.empty:\n",
    "# #     closing_df.to_pickle('SSE companies closing prices.pkl')\n",
    "\n",
    "# # cut into parts\n",
    "# closing_df1 = closing_df.iloc[:, :int(np.floor(len(closing_df) / 2))]\n",
    "# closing_df2 = closing_df.iloc[:, int(np.floor(len(closing_df) / 2)):]\n",
    "\n",
    "# # save as pkl files\n",
    "# if not closing_df1.empty and closing_df2.empty:\n",
    "#     closing_df1.to_pickle('data/01 SSE companies closing prices.pkl')\n",
    "#     closing_df2.to_pickle('data/02 SSE companies closing prices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5499914-ec75-40ad-b918-35031e3c7e43",
   "metadata": {},
   "source": [
    "Note: The code above takes around 30-45 minutes to completely run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85182-8bae-43d6-811d-59d8d4c9fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
